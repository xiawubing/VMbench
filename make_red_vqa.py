#!/usr/bin/env python3
"""
make_red_vqa.py â€“ ç”Ÿæˆã€çº¢åœˆåŒºåŸŸã€ç›¸å…³çš„åŒ»å­¦è§†è§‰é—®ç­” (VQA) MCQ æ•°æ®é›†

åŸºäºæ”¹è¿›çš„åŒ»å­¦ VQA ä¸“å®¶ promptï¼Œä¸“æ³¨äº ROI (Region of Interest) åˆ†æï¼š
* è¾“å…¥éœ€è¦åŒ…å« ROI åæ ‡ (roi_bbox) å’Œå¯é€‰çš„ ROI æè¿° (roi_caption)
* ç”Ÿæˆå¤šæ ·åŒ–çš„åŒ»å­¦ MCQï¼Œæ¶µç›–ç»†èƒç±»å‹ã€å…ç–«ç»„åŒ–æ ‡è®°ã€ç—…ç†è¯Šæ–­ã€å½¢æ€ç‰¹å¾ç­‰
* æ”¯æŒå¤šé€‰ç­”æ¡ˆï¼Œç¡®ä¿ä¸“ä¸šåŒ»å­¦æœ¯è¯­çš„å‡†ç¡®æ€§
* è¾“å‡ºæ ¼å¼ï¼šJSON æ•°ç»„ï¼ŒåŒ…å«é—®é¢˜ã€é€‰é¡¹ã€æ­£ç¡®ç­”æ¡ˆç´¢å¼•å’Œ ROI åæ ‡

**æ–°å¢åŠŸèƒ½**ï¼šæ”¯æŒå®æ—¶å‚¨å­˜æ¨¡å¼ (--realtime_save)
* å®æ—¶æ¨¡å¼ï¼šæ¯å¤„ç†ä¸€å¼ å›¾ç‰‡å°±ç«‹å³ä¿å­˜åˆ°æ–‡ä»¶ï¼Œé¿å…ç¨‹åºä¸­æ–­å¯¼è‡´æ•°æ®ä¸¢å¤±
* æ‰¹é‡æ¨¡å¼ï¼šä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å›¾ç‰‡åä¿å­˜ï¼ˆé»˜è®¤æ¨¡å¼ï¼‰

ä¾èµ–
----
```
pip install google-generativeai pillow tqdm pandas
```

ä½¿ç”¨ç¤ºä¾‹
--------
python make_red_vqa.py \\
    --img_dir red_circle \\
    --qa_json quiltvqa_red_test_w_ans.jsonl \\
    --out quiltvqa_red_bench.jsonl \\
    --realtime_save
"""

from __future__ import annotations
import os
import json
import argparse
import re
from pathlib import Path
from typing import List, Dict, Any

import google.generativeai as genai  # Gemini
import PIL.Image  # noqa: E402
from tqdm import tqdm  # noqa: E402

# ---------- Prompt æ¨¡æ¿ ---------- #
PROMPT_TEMPLATE = (
    "You are a senior medical Visual Question Answering (VQA) annotation expert, skilled at interpreting histology / microscopy images and crafting high-quality questions focused on a Region of Interest (ROI) highlighted by a red circle.\n\n"
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
    "[INPUT]\n"
    "1. image with red circle    : the original image in which a red circle marks the ROI\n"
    "2. roi_caption  : a brief textual description of what is visible inside the red circle (may be empty)\n"
    "3. n            : the desired number of questions to generate (default 5)\n\n"
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
    "[TASK]\n"
    "â–º **Zoom in and closely inspect the ROI** (use roi_caption as a reference if provided) to identify the most diagnostically relevant or visually prominent details.  \n"
    "â–º For **this specific ROI**, generate *{n}* sets of **multiple-choice questions** (more than one correct answer allowed). Each stem and its options must meet all of the following criteria:\n\n"
    "  1. **Strong relevance & verifiability**  \n"
    "     â€¢ A reader can answer solely by examining the ROI (with roi_caption as auxiliary information).  \n"
    "     â€¢ The stem and options must not rely on details that cannot be determined from the ROI.\n\n"
    "  2. **Diversity & appropriateness**  \n"
    "     â€¢ Each question should address a different facet of the ROI. After examining the image, select **one or two** of the five viewpoints below for each question so that the full set is varied:  \n"
    "       a. Predominant cell types / cellular proportions  \n"
    "       b. Immunohistochemical markers / staining patterns  \n"
    "       c. Most likely diagnoses or pathological entities  \n"
    "       d. Characteristic morphological features (nuclear or cytoplasmic details, structural arrangements, etc.)  \n"
    "       e. Vascularâ€“stroma or inflammationâ€“stroma relationships  \n"
    "     â€¢ You are **not** required to cover every category; decide based on what the image actually shows.\n\n"
    "  3. **Option design**  \n"
    "     â€¢ Provide at least two options per question, in random order. Distractors should be plausible yet incorrect.  \n"
    "     â€¢ Mark all correct options with **answer_index**, an array of their indices in the \"options\" list.\n\n"
    "  4. **Professional accuracy**  \n"
    "     â€¢ Use standard medical terminology for stains, markers, and entities.  \n"
    "     â€¢ Do not introduce features absent from the image; if a detail is uncertain, omit that category.\n\n"
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
    "[OUTPUT FORMAT]\n"
    "Return **only** a top-level JSON array; no extra commentary or metadata.  \n"
    "Each element must have this structure:\n\n"
    "{{\n"
    "  \"question\"     : \"<question stem>\",\n"
    "  \"options\"      : [\"<option 1>\", \"<option 2>\", â€¦],\n"
    "  \"answer_index\" : [<indices of correct options>],\n"
    "  \"region\"       : [x1, y1, x2, y2]    // identical to input roi_bbox\n"
    "}}\n\n"
    "âš ï¸ Output strictly the JSON arrayâ€”do not add explanations before or after.\n\n"
    "Provided Info:\n"
    "â€¢ Image resolution: {width}Ã—{height}\n"
    "â€¢ ROI coordinates: {roi_bbox}\n"
    "â€¢ ROI caption: {roi_caption}\n"
    "â€¢ Number of questions: {n}\n\n"
    "Begin now!"
)


# ---------- æ ¸å¿ƒå‡½æ•° ---------- #

def ask_llm_for_mcq(
    pil_img: "PIL.Image.Image",
    roi_bbox: List[int],
    roi_caption: str = "",
    model_name: str = "gemini-2.5-pro",
    n: int = 5,
    temperature: float = 0.4,
) -> List[Dict[str, Any]]:
    """è°ƒç”¨ Gemini ç”Ÿæˆ MCQ åˆ—è¡¨ã€‚"""
    width, height = pil_img.size
    prompt = PROMPT_TEMPLATE.format(
        n=n,
        width=width,
        height=height,
        roi_bbox=roi_bbox,
        roi_caption=roi_caption if roi_caption else "No caption provided",
    )

    model = genai.GenerativeModel(model_name)
    response = model.generate_content(
        [prompt, pil_img],
        generation_config=genai.GenerationConfig(temperature=temperature),
    )

    text = response.text.strip()
    print(f"ğŸ” åŸå§‹æ¨¡å‹è¾“å‡º: {text[:200]}...", flush=True)

    # ç§»é™¤å¯èƒ½çš„ Markdown åŒ…è£¹
    if text.startswith("```"):
        text = re.sub(r"^```[a-zA-Z]*\n?", "", text)
        text = re.sub(r"\n?```$", "", text)

    # æˆªå–è‡³ç¬¬ä¸€ä¸ª '[' ä»¥é¿å…æ¨¡å‹é—²èŠ
    idx = text.find("[")
    if idx > 0:
        text = text[idx:]

    # å°è¯•å¤šç§JSONè§£æç­–ç•¥
    try:
        data = json.loads(text)
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤: {e}", flush=True)
        print(f"ğŸ” åŸå§‹æ–‡æœ¬: {text[:500]}...", flush=True)
        
        # ç­–ç•¥1ï¼šå°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
        try:
            # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ–‡æœ¬
            text = text.strip()
            if text.endswith("ã€‚"):
                text = text[:-1]
            
            # å°è¯•è§£æ
            data = json.loads(text)
        except json.JSONDecodeError:
            # ç­–ç•¥2ï¼šå°è¯•æŸ¥æ‰¾JSONæ•°ç»„çš„å¼€å§‹å’Œç»“æŸ
            try:
                start_idx = text.find("[")
                end_idx = text.rfind("]")
                if start_idx >= 0 and end_idx > start_idx:
                    json_text = text[start_idx:end_idx+1]
                    data = json.loads(json_text)
                else:
                    raise json.JSONDecodeError("No valid JSON array found", text, 0)
            except json.JSONDecodeError:
                # ç­–ç•¥3ï¼šå°è¯•æŸ¥æ‰¾JSONå¯¹è±¡çš„å¼€å§‹å’Œç»“æŸ
                try:
                    start_idx = text.find("{")
                    end_idx = text.rfind("}")
                    if start_idx >= 0 and end_idx > start_idx:
                        json_text = text[start_idx:end_idx+1]
                        data = json.loads(json_text)
                    else:
                        raise json.JSONDecodeError("No valid JSON object found", text, 0)
                except json.JSONDecodeError:
                    # ç­–ç•¥4ï¼šå¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤çš„MCQç»“æ„
                    print(f"âŒ JSONä¿®å¤å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„", flush=True)
                    data = [{
                        "question": f"What is visible in the highlighted region of this image?",
                        "options": ["Pathological tissue", "Normal tissue", "Cannot determine"],
                        "answer_index": [0],
                        "region": roi_bbox
                    }]
    
    # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨æ ¼å¼
    if not isinstance(data, list):
        data = [data]
    
    return data


def process_dataset(
    img_dir: Path,
    qa_json: Path,
    out_path: Path,
    model_name: str,
    n: int,
    temperature: float,
    realtime_save: bool = False,
) -> None:
    # è¯»å– JSONL æ ¼å¼çš„ QA æ•°æ®
    qa_data: List[Dict[str, Any]] = []
    with open(qa_json, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:  # è·³è¿‡ç©ºè¡Œ
                qa_data.append(json.loads(line))

    qa_lookup = {entry["image"]: entry for entry in qa_data}
    out_path.parent.mkdir(parents=True, exist_ok=True)

    # å®æ—¶å‚¨å­˜æ¨¡å¼ï¼šæ¯å¤„ç†ä¸€å¼ å›¾ç‰‡å°±ç«‹å³ä¿å­˜
    if realtime_save:
        print("ğŸ”„ å¯ç”¨å®æ—¶å‚¨å­˜æ¨¡å¼")
        for img_path in tqdm(sorted(img_dir.glob("*.jpg"))):
            key = img_path.name
            if key not in qa_lookup:
                print(f"âš ï¸ è·³è¿‡ {key} â€“ æœªæ‰¾åˆ°å¯¹åº” QA", flush=True)
                continue

            pil_img = PIL.Image.open(img_path)
            
            # Extract ROI information from QA data
            qa_entry = qa_lookup[key]
            roi_bbox = qa_entry.get("roi_bbox", [0, 0, pil_img.width, pil_img.height])  # Default to full image if not specified
            roi_caption = qa_entry.get("roi_caption", "")
            
            try:
                mcq_items = ask_llm_for_mcq(
                    pil_img=pil_img,
                    roi_bbox=roi_bbox,
                    roi_caption=roi_caption,
                    model_name=model_name,
                    n=n,
                    temperature=temperature,
                )
                
                # éªŒè¯MCQé¡¹ç›®æ ¼å¼
                if not mcq_items or not isinstance(mcq_items, list):
                    print(f"âš ï¸ {key}: ç”Ÿæˆçš„MCQé¡¹ç›®æ ¼å¼æ— æ•ˆï¼Œè·³è¿‡", flush=True)
                    continue
                    
            except Exception as e:
                print(f"âŒ ç”Ÿæˆå¤±è´¥ {key}: {e}", flush=True)
                continue

            # å®æ—¶å†™å…¥å½“å‰å›¾ç‰‡çš„æ‰€æœ‰MCQé¡¹ç›®
            with open(out_path, "a", encoding="utf-8") as fout:
                for item in mcq_items:
                    record = {
                        "image_path": str(img_path.relative_to(img_dir.parent)),
                        **item,
                    }
                    fout.write(json.dumps(record, ensure_ascii=False) + "\n")
                    fout.flush()  # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒºï¼Œç¡®ä¿ç«‹å³å†™å…¥ç£ç›˜
            
            print(f"âœ… å·²å®æ—¶ä¿å­˜ {key} çš„ {len(mcq_items)} ä¸ªMCQé¡¹ç›®", flush=True)
    
    # æ‰¹é‡å¤„ç†æ¨¡å¼ï¼šä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å›¾ç‰‡
    else:
        print("ğŸ“¦ ä½¿ç”¨æ‰¹é‡å¤„ç†æ¨¡å¼")
        with open(out_path, "w", encoding="utf-8") as fout:
            for img_path in tqdm(sorted(img_dir.glob("*.jpg"))):
                key = img_path.name
                if key not in qa_lookup:
                    print(f"âš ï¸ è·³è¿‡ {key} â€“ æœªæ‰¾åˆ°å¯¹åº” QA", flush=True)
                    continue

                pil_img = PIL.Image.open(img_path)
                
                # Extract ROI information from QA data
                qa_entry = qa_lookup[key]
                roi_bbox = qa_entry.get("roi_bbox", [0, 0, pil_img.width, pil_img.height])  # Default to full image if not specified
                roi_caption = qa_entry.get("roi_caption", "")
                
                try:
                    mcq_items = ask_llm_for_mcq(
                        pil_img=pil_img,
                        roi_bbox=roi_bbox,
                        roi_caption=roi_caption,
                        model_name=model_name,
                        n=n,
                        temperature=temperature,
                    )
                    
                    # éªŒè¯MCQé¡¹ç›®æ ¼å¼
                    if not mcq_items or not isinstance(mcq_items, list):
                        print(f"âš ï¸ {key}: ç”Ÿæˆçš„MCQé¡¹ç›®æ ¼å¼æ— æ•ˆï¼Œè·³è¿‡", flush=True)
                        continue
                        
                except Exception as e:
                    print(f"âŒ ç”Ÿæˆå¤±è´¥ {key}: {e}", flush=True)
                    continue

                for item in mcq_items:
                    record = {
                        "image_path": str(img_path.relative_to(img_dir.parent)),
                        **item,
                    }
                    fout.write(json.dumps(record, ensure_ascii=False) + "\n")


# ---------- CLI ---------- #

def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Generate red-circle MCQ VQA dataset from JSONL input")
    parser.add_argument("--img_dir", required=True, type=Path, help="Folder containing images (PNG/JPG)")
    parser.add_argument("--qa_json", required=True, type=Path, help="Existing QA JSONL file with 'image', 'roi_bbox', and 'roi_caption' fields")
    parser.add_argument("--out", required=True, type=Path, help="Output JSONL file path")
    parser.add_argument("--model", default="gemini-2.5-pro", help="Gemini model name")
    parser.add_argument("-n", type=int, default=3, help="Number of MCQ pairs per image")
    parser.add_argument("--temp", type=float, default=0.4, help="Sampling temperature")
    parser.add_argument("--api_key_env", default="GEMINI_API_KEY", help="Env var for API key")
    parser.add_argument("--realtime_save", action="store_true", help="Enable realtime save mode")
    return parser.parse_args()


def init_gemini(api_key_env: str) -> None:
    api_key = os.getenv(api_key_env)
    if not api_key:
        raise EnvironmentError(
            f"ç¯å¢ƒå˜é‡ {api_key_env} æœªè®¾ç½®ã€‚è¯· export {api_key_env}='YOUR_GEMINI_KEY'"
        )
    genai.configure(api_key=api_key)


def main():
    args = parse_args()
    init_gemini(args.api_key_env)

    process_dataset(
        img_dir=args.img_dir,
        qa_json=args.qa_json,
        out_path=args.out,
        model_name=args.model,
        n=args.n,
        temperature=args.temp,
        realtime_save=args.realtime_save,
    )


if __name__ == "__main__":
    main()
